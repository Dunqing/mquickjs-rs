# Benchmark Analysis: Rust vs C Implementation

This document explains the performance differences between MQuickJS-RS (Rust) and the original MQuickJS (C).

## Benchmark Results

**Machine**: Apple M4 Max, 64 GB RAM, macOS

| Benchmark | Rust (s) | C (s) | Ratio | Winner |
|-----------|----------|-------|-------|--------|
| fib | 0.018 | 0.059 | 0.30x | Rust 3.3x faster |
| loop | 0.019 | 0.035 | 0.54x | Rust 1.9x faster |
| json | 0.022 | 0.024 | 0.93x | Rust 8% faster |
| string | 0.017 | 0.017 | 1.01x | Equal |
| object | 0.018 | 0.017 | 1.08x | Equal |
| closure | 0.018 | 0.016 | 1.10x | Equal |
| array | 0.019 | 0.017 | 1.15x | C 15% faster |
| sieve | 0.039 | 0.022 | 1.73x | C 73% faster |

## Why Rust is Faster on `fib` (3.3x)

### The Key Difference: Recursion Handling

**C Implementation** (mquickjs.c, line 68):
```c
#define JS_MAX_CALL_RECURSE 8
```

The original MQuickJS limits C stack recursion to **only 8 levels**. When this limit is reached, it throws "C stack overflow". For `fib(30)` which requires thousands of recursive calls, the C implementation must use a complex trampoline/continuation mechanism to avoid actual stack overflow.

**Rust Implementation**:
```rust
call_stack: Vec<CallFrame>,  // Heap-allocated frame stack
```

The Rust version uses a **heap-allocated call stack** (a `Vec<CallFrame>`). Each function call just pushes a lightweight `CallFrame` struct to the vector - no actual stack recursion. This is a "stackless" interpreter design.

### Comparison

| Aspect | C (mquickjs) | Rust (mquickjs-rs) |
|--------|--------------|-------------------|
| Recursion limit | 8 C stack frames | Limited only by heap memory |
| Deep recursion | Must save/restore interpreter state | Just push/pop Vec element |
| Function call overhead | Complex continuation handling | Simple `Vec::push()` |
| Memory locality | State scattered across C stack | Compact CallFrame structs |

The stackless design in Rust means:
- No C/Rust stack growth during JS recursion
- Constant-time function call overhead
- Better cache locality for call frames

## Why Rust is Faster on `loop` (1.9x)

### 1. LLVM Optimizations

Rust's release build with LTO (`lto = true` in Cargo.toml) aggressively optimizes the interpreter loop. The `opt-level = 3` setting enables maximum optimization.

### 2. Simpler Integer Fast Path

**Rust** - Clean pattern matching:
```rust
fn op_add(&self, a: Value, b: Value) -> InterpreterResult<Value> {
    match (a.to_i32(), b.to_i32()) {
        (Some(va), Some(vb)) => {
            if let Some(result) = va.checked_add(vb) {
                Ok(Value::int(result))
            } else {
                Err(InterpreterError::InternalError("integer overflow".into()))
            }
        }
        _ => Err(InterpreterError::TypeError("cannot add non-numbers".into())),
    }
}
```

**C** - Must check both integer AND short float paths:
```c
CASE(OP_add):
    if (likely(JS_VALUE_IS_BOTH_INT(op1, op2))) {
        int r;
        if (unlikely(__builtin_add_overflow((int)op1, (int)op2, &r)))
            goto add_slow;
        sp[1] = (uint32_t)r;
    } else if (JS_VALUE_IS_BOTH_SHORT_FLOAT(op1, op2)) {
        // Short float path...
    } else {
        goto add_slow;
    }
```

The C version has additional branching for short float support that the Rust version doesn't need.

### 3. Branch Prediction

Rust's `match` on opcode compiles to efficient jump tables. The LLVM backend can better optimize the dispatch loop compared to the C switch statement with computed gotos.

## Why C is Faster on `sieve` (1.7x) and `array` (1.15x)

### Optimizations Applied

We've applied several optimizations to reduce the gap:

1. **Unsafe stack operations**: `pop_unchecked()`, `pop2_unchecked()`, `pop3_unchecked()` for hot paths
2. **Unsafe value extraction**: `to_i32_unchecked()`, `to_array_idx_unchecked()` after type checks
3. **Unchecked array access**: `get_unchecked()` in GetArrayEl/PutArrayEl after bounds validation

```rust
// Optimized fast path in GetArrayEl
if arr.is_array() && idx.is_int() {
    let arr_idx = unsafe { arr.to_array_idx_unchecked() };
    let index = unsafe { idx.to_i32_unchecked() };
    if index >= 0 {
        let array = unsafe { self.get_array_unchecked(arr_idx) };
        if index < array.len() {
            // SAFETY: We just checked index < len
            unsafe { *array.get_unchecked(index) }
        }
    }
}
```

### Remaining Gap

Even with optimizations, C maintains a lead due to:

1. **Method call overhead**: Each `array.push()` in JavaScript requires GetField lookup + native function call
2. **Type tag checking**: Every operation still checks value types, even in fast paths
3. **Memory allocation**: C uses custom arena allocator vs Rust's general-purpose `Vec`

The C implementation uses direct pointer arithmetic with no runtime checks:

```c
// Direct memory access, no bounds check
val = arr->values[i];
```

## Summary

| Category | Winner | Reason |
|----------|--------|--------|
| **Recursion-heavy** (fib) | Rust | Stackless interpreter design vs 8-frame limit |
| **Loop-heavy** (loop) | Rust | LLVM optimizations, simpler integer path |
| **JSON parsing** | Rust | String handling optimizations |
| **Object/String/Closure** | Tie | Similar implementation strategies |
| **Array-heavy** (array, sieve) | C | Method call overhead, custom allocator |

## Potential Further Optimizations

1. âœ… **Unsafe array access**: Implemented `get_unchecked()` in hot paths
2. **Custom allocator**: Implement arena allocation similar to C version
3. **Inline push**: Specialize GetField for common array methods to avoid lookup
4. **Profile-guided optimization**: Use PGO to optimize the interpreter dispatch loop
